{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Předpřipravený tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = \"Proč chceš stát na dešti? Není o co stát.\"\n",
    "en = \"They refuse to permit us to obtain the refuse permit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = nltk.word_tokenize(en)\n",
    "en_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(en_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpy.morphodita import Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "czech_pos_tagger = Tagger(\"/home/lukes/edu/python/czech-morfflex-pdt-161115/czech-morfflex-pdt-161115-pos_only.tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(czech_pos_tagger.tag(cs, sents=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otagovaný korpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.brown.tagged_words(tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možnost načíst si věty z otagovaného korpusu budeme potřebovat při trénování a testování našich vlastních taggerů (testování = porovnávání výstupu našeho taggeru s ručně označkovaným, tzv. **zlatým** standardem).\n",
    "\n",
    "## Trénovací a testovací data\n",
    "\n",
    "Tagger je potřeba trénovat a testovat na různých sadách dat, jinak by se nám mohlo stát, že vytvoříme tagger, který se do detailu naučí všechna specifika našich trénovacích dat a bude na nich velmi úspěšný, ale nezjistíme, že špatně generalizuje a že na jakémkoli jiném vstupu je jeho úspěšnost mnohem horší."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ~/edu/python/pdt3.*.vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vert_sents(path):\n",
    "    \"\"\"Načte korpus jako seznam seznamů (= vět) ntic (= pozic).\"\"\"\n",
    "    sents = []\n",
    "    with open(path) as file:\n",
    "        for line in file:\n",
    "            line = line.strip(\"\\n\")\n",
    "            if line == \"<s>\":\n",
    "                sent = []\n",
    "            elif line == \"</s>\":\n",
    "                sents.append(sent)\n",
    "            elif \"\\t\" in line:\n",
    "                word, _, tag = line.split(\"\\t\")\n",
    "                pos = tag[0]\n",
    "                sent.append((word, pos))\n",
    "    return sents    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = vert_sents(\"/home/lukes/edu/python/pdt3.train.vrt\")\n",
    "test = vert_sents(\"/home/lukes/edu/python/pdt3.test.vrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vlastní tagger\n",
    "\n",
    "Jak k problému vůbec přistoupit? Na jakém principu by měl tagger fungovat? Představte si, že chcete vymyslet formální postup, podle něhož by bez znalosti daného jazyka mohl značkování provést i člověk, ale místo člověku ho pak povíte počítači. Nesnažte se rovnou vyřešit všechno, zvolte \"inženýrský\" přístup -- přednostně se snažte identifikovat a řešit části problému, které mají při minimálním vynaloženém úsilí maximální účinek. Účinek v tomto případě měříme úspěšností taggeru -- procentem značek přidělených tak, aby odpovídaly referenčnímu korpusu (zlatému standardu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nejčastější POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fdist = nltk.FreqDist(p for s in train for _, p in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_tagger(word):\n",
    "    return pos_fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger(\"kočka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger(\"sadlfkas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nejčastější POS pro daný tvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_cfdist = nltk.ConditionalFreqDist((w, p) for s in train for w, p in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_cfdist[\"včera\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_cfdist[\"stát\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_cfdist[\"asdfsaf\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Přes regulární výrazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tagger = nltk.RegexpTagger([\n",
    "    (r\".*ání$\", \"N\"),\n",
    "    (r\".*[áí]t$\", \"V\"),\n",
    "    (r\"a|i|(proto|tak)?že|když|aby|nebo|ani\", \"J\"),\n",
    "], backoff=nltk.DefaultTagger(\"N\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tagger.tag([\"tání\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tagger.tag([\"kočka\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tagger.evaluate(list(vert_sents(\"/home/lukes/edu/python/pdt3.test.vrt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gramový tagger\n",
    "\n",
    "N-gramové značkování funguje tak, že počítač naučíme rozpoznávat pravidelnosti v tom, jaké morfologické značky se nejčastěji objevují ve kterých kontextech. Kontextem zde míníme typicky aktuální tvar, který se snažíme označkovat, a sekvenci předchozích již stanovených značek. Např. pro trigramový tagger, který za kontext považuje aktuální tvar + značky na předchozích **dvou** pozicích (spolu s aktuální to dává tři, proto **tri**gramový) si můžeme situaci znázornit následovně:\n",
    "\n",
    "![n-gram tagger](http://www.nltk.org/images/tag-context.png)\n",
    "\n",
    "Pokud se taková data snažíme reprezentovat v Pythonu, dobrou volbou může být podmíněná frekvenční distribuce (`nltk.ConditionalFreqDist`). Podmínky odpovídají jednotlivým kontextům a uvnitř každé podmínky máme frekvenční distribuci morfologických značek, které jsme v daném kontextu zaznamenali. Z takovýchto dat jsme pak schopni určit, že např. pro kontext `(aktuální_slovo=\"pláče\", předcházející_tag=\"R (předložka)\")` je nepravděpodobnější tag (pro aktuální slovo, tj. \"pláče\") `N (substantivum)`.\n",
    "\n",
    "Některé kontexty budou jednoznačné, tj. frekvenční distribuce v tomto kontextu přípustných tagů bude obsahovat jen jeden prvek. Ale určitá část (i v závislosti na velikosti trénovacích dat) bude patrně víceznačná:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_cfdist = nltk.ConditionalFreqDist(((b1.pos, b2.word), b2.pos) for s in vert_sents(\"/home/lukes/edu/python/pdt3.train.vrt\") for b1, b2 in nltk.bigrams(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in bigram_cfdist.items():\n",
    "    if len(v) > 1:\n",
    "        print(k, dict(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gramové taggery v NLTK\n",
    "\n",
    "N-gramové taggery lze v NLTK natrénovat velmi jednoduše a pospojovat je dohromady pomocí tzv. \"backoffu\". To je metoda, která řeší nedostatek dat (\"data sparsity\"): pokud nemůžeme pro aktuální kontext vybrat značku na základě bigramového taggeru, protože jsme tento kontext v trénovacích datech jednoduše nepotkali, zkusíme unigramový; pokud selže i ten (= slovní tvar jsme v trénovacích datech prostě ani jednou nepotkali), zvolíme pro pozici nějakou defaultní značku (typicky nejčastější slovní druh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = nltk.BigramTagger(train)\n",
    "# metoda evaluate spočítá úspěšnost taggeru -- zde je potřeba použít jiná\n",
    "# data než trénovací, aby byl údaj spolehlivý\n",
    "t2.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger(\"N\")\n",
    "t1 = nltk.UnigramTagger(train, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train, backoff=t1)\n",
    "t2.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vlastní tagger\n",
    "\n",
    "Abychom se trochu pocvičili v Pythonu, zkusili jsme si napsat vlastní tagger(y). Celá metoda je (jako většina metod v NLP) založená na chytrém využití frekvencí: spočítáme frekvence kontextů a odpovídajících značek v trénovacích datech a pak se z nich snažíme zpětně odvodit odpovídající značky pro kontexty, které potkáváme při značkování nových vět."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# frekvenční distribuce: počet výskytů různých jevů, např. slov v textu\n",
    "nltk.FreqDist([\"kočka\", \"stát\", \"kočka\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# podmíněná frekvenční distribuce: počet výskytů různých jevů za různých podmínek,\n",
    "# např. slovnědruhových značek v kontextu slovního tvaru, který se aktuálně snažíme\n",
    "# opatřit značkou\n",
    "cfd = nltk.ConditionalFreqDist([(\"stát\", \"N\"), (\"kočka\", \"N\"), (\"stát\", \"V\"), (\"stát\", \"V\")])\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# pokud se díváme na tvar \"stát\", tak na základě \"trénovacích dat\" (= těch čtyř\n",
    "# pozic v předchozí buňce) je nejpravděpodobnější značka \"V\"\n",
    "cfd[\"stát\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# u tvaru, který jsme neviděli, nelze stanovit `.max()`, dojde tedy k chybě\n",
    "cfd[\"bambule\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# chybu lze odchytit pomocí syntaktického konstruktu `try ... except`\n",
    "word = \"bambule\"\n",
    "try:\n",
    "    cfd[word].max()\n",
    "except ValueError:\n",
    "    print(f\"Na slovo {word} jsme bohužel v trénovacích datech nenarazili :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Unigramový tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_uni(data):\n",
    "    \"\"\"Natrénuje unigramový tagger.\"\"\"\n",
    "    cfd = nltk.ConditionalFreqDist()\n",
    "    for sent in data:\n",
    "        for word, tag in sent:\n",
    "            cfd[word.lower()][tag] += 1\n",
    "    return cfd\n",
    "\n",
    "# též možno zapsat úsporněji takto\n",
    "def train_uni2(data):\n",
    "    \"\"\"Natrénuje unigramový tagger.\"\"\"\n",
    "    return nltk.ConditionalFreqDist(\n",
    "        (word.lower(), tag)\n",
    "        for sent in data\n",
    "        for (word, tag) in sent\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tag_uni(sent, uni_cfd):\n",
    "    \"\"\"Otaguje větu pomocí unigramového taggeru.\"\"\"\n",
    "    tagged_sent = []\n",
    "    for word in sent:\n",
    "        try:\n",
    "            tag = uni_cfd[word.lower()].max()\n",
    "        except ValueError:\n",
    "            # pokud tvar neznáme, přiřadíme mu tag \"N\"\n",
    "            tag = \"N\"\n",
    "        tagged_sent.append((word, tag))\n",
    "    return tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uni_tagger = train_uni(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# s jakými tagy jsme v trénovacích datech viděli tvar \"V\"?\n",
    "uni_tagger[\"V\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# s jakými tagy jsme v trénovacích datech viděli tvar \"v\"?\n",
    "uni_tagger[\"v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tag_uni(\"Už zase frunakulózně prší .\".split(), uni_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bigramový tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# kontext může být i složitější, třeba předchozí tag + aktuální tvar;\n",
    "# v takovém případě ho budeme reprezentovat jako ntici\n",
    "context = (\"A\", \"stát\")\n",
    "tag = \"N\"\n",
    "cfd = nltk.ConditionalFreqDist([(context, tag)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd[(\"A\", \"stát\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cfd[(\"A\", \"stát\")].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cfd[(\"R\", \"stát\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# taky budeme potřebovat mít možnost nějak pohodlně procházet věty po\n",
    "# bigramech a zachytit, která slova jsme potkali na začátcích vět;\n",
    "# s tím prvním nám pomůže funkce `nltk.bigrams()` (pozor, vrací\n",
    "# generátor!), s tím druhým si poradíme tak, že na začátek věty vždy\n",
    "# přilepíme falešnou pozici s nějakými speciálními hodnotami pro tvar\n",
    "# a značku, podle nichž se pozná začátek věty\n",
    "sent = train[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# napadne vás důvod, proč zde vytváříme konkatenací nový seznam, místo\n",
    "# abychom do toho stávajícího vložili na začátek ntici `(None, None)`\n",
    "# (tj. `sent.insert(0, (None, None))`)?\n",
    "sent = [(None, None)] + sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i, (b1, b2) in enumerate(nltk.bigrams(sent)):\n",
    "    print(f\"Bigram č. {i+1}\\nPrvní půlka bigramu: {b1}\\nDruhá půlka bigramu: {b2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_bi(data):\n",
    "    \"\"\"Natrénuje bigramový tagger.\"\"\"\n",
    "    cfd = nltk.ConditionalFreqDist()\n",
    "    for sent in data:\n",
    "        sent = [(None, None)] + sent\n",
    "        for (_, previous_tag), (current_word, current_tag) in nltk.bigrams(sent):\n",
    "            cfd[(previous_tag, current_word.lower())][current_tag] += 1\n",
    "    return cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bi_tagger = train_bi(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# tagy, které jsme viděli pro slovní tvar \"v\" na začátku věty (= předchozí\n",
    "# tag je `None`)\n",
    "bi_tagger[(None, \"v\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for (prev_tag, curr_word), fd in bi_tagger.items():\n",
    "    if prev_tag is not None and curr_word == \"v\":\n",
    "        print(f\"V kontextu předcházející značky {prev_tag} má tvar 'v' následující \"\n",
    "              f\"frekvenční distribuci možných značek:\\n{fd!r}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Jak by mohla tedy vypadat funkce `tag_bi()`, která otaguje větu pomocí bigramového modelu? (Řešení viz poznámky z hodiny.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
